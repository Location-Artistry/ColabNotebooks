{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "waterDataExport.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qAzr6mSB6Zoq",
        "l5KcKTRMumdG",
        "D9vNJrKMjZ3c",
        "c2Ha3EWdla7Q",
        "nybZ5ek1_Dvz",
        "WJWWtg96-iOa",
        "fAjJ9kfABtZF",
        "wnjboz2Cey0l",
        "OkVz4g17ebjt"
      ],
      "authorship_tag": "ABX9TyMfXyg+UflDLbCGEpxSHFCv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Location-Artistry/ColabNotebooks/blob/master/waterDataExport.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAzr6mSB6Zoq",
        "colab_type": "text"
      },
      "source": [
        "#**Working Water Data Pandas AWQMS Export**\n",
        "Updated August 12th - Working with pandas dataframe exporting to excel   \n",
        "Working function to run download and CSV formatting in pandas   \n",
        "**8-14 Completed: Download & Export Functions, QuickMap Display**\n",
        "**8-25 delMultiple, updated Kzoo Dashboard Status**   \n",
        "**8-25 This Notebook has most current Python Functions!!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5KcKTRMumdG",
        "colab_type": "text"
      },
      "source": [
        "# Install and Import Libraries\n",
        "**RUN FIRST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyTdckWPWdHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install xlsxwriter\n",
        "!pip install xlrd\n",
        "!pip install openpyxl\n",
        "!pip install arcgis\n",
        "#!pip install pdfkit\n",
        "#import pdfkit\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import os\n",
        "import datetime as dt\n",
        "import time as tm\n",
        "import math\n",
        "from arcgis.gis import GIS, Item\n",
        "from arcgis.env import active_gis\n",
        "from arcgis.features import FeatureLayerCollection\n",
        "from arcgis.mapping import WebMap\n",
        "from IPython.display import display\n",
        "import getpass\n",
        "from pathlib import Path\n",
        "from zipfile import ZipFile\n",
        "from openpyxl import load_workbook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9vNJrKMjZ3c",
        "colab_type": "text"
      },
      "source": [
        "# Python Functions from my ArcGIS Python Colab Notebook  \n",
        "**MUST RUN THIS CELL AFTER INSTALL AND IMPORT THEN - userLogin() -**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4Ffhx69jTSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Collection of all ArcGIS Python API Helper Functions\n",
        "# user login functions, ask if user would like additional logins\n",
        "def userLogin():\n",
        "    userID = input(f'ArcGIS Online USER ID: ')\n",
        "    passWord = getpass.getpass('PASSWORD: ')\n",
        "    try:\n",
        "        global gis\n",
        "        gis = GIS(\"https://www.arcgis.com\", userID, passWord)\n",
        "        print(f'SUCCESS - CONNECTED TO: {gis.users.me.username} ACCOUNT as <gis>')\n",
        "        print(gis)\n",
        "        addUsers = input(f'Additional User Login(YES/NO)? ')\n",
        "        if addUsers.upper() == 'YES':\n",
        "            additionalUserLogin()\n",
        "        else:\n",
        "            print(f'YOU MAY NOW PROCEED...')\n",
        "    except:\n",
        "        print(f'ERROR DID NOT CONNECT TO: {userID}')\n",
        "\n",
        "def additionalUserLogin():\n",
        "    userID = input(f'ArcGIS Online USER ID: ')\n",
        "    passWord = getpass.getpass('PASSWORD: ')\n",
        "    try:\n",
        "        global gis2\n",
        "        gis2 = GIS(\"https://www.arcgis.com\", userID, passWord)\n",
        "        print(f'SUCCESS - CONNECTED TO: {gis2.users.me.username} ACCOUNT as <gis2>')\n",
        "        print(gis2)\n",
        "    except:\n",
        "        print(f'ERROR DID NOT CONNECT TO: {userID}')\n",
        "\n",
        "# get list of all owner AGOL items, print list with title, id, type, and categories\n",
        "def getUserContent(gisInfo):\n",
        "    try:\n",
        "        my_content = gisInfo.content.search(query=\"owner:\" + gisInfo.users.me.username, item_type=\"\", max_items=200)\n",
        "        for x in my_content:\n",
        "            strMod = str(x.modified)\n",
        "            stampInt = int(strMod[0:10])\n",
        "            print(f'{x.title} - {x.id} - {x.type} - {x.categories} - {dt.datetime.fromtimestamp(stampInt)}')\n",
        "    except:\n",
        "        print('ERROR could not get user content')\n",
        "\n",
        "# Clone item using id of item passed to function\n",
        "def cloneItem(gisInfo, gisInfo2, cloneID):    \n",
        "    try:\n",
        "        itemToClone = gisInfo.content.get(cloneID)\n",
        "        print('Cloning:' + itemToClone.title + ' - ' + itemToClone.id + ' -',itemToClone.type)\n",
        "        clonedItem = gisInfo2.content.clone_items(items=[itemToClone])\n",
        "        print(f'Cloned Item: {clonedItem[0]}')\n",
        "        #return clonedItem\n",
        "    except:\n",
        "        print('ERROR Could Not Clone')\n",
        "\n",
        "# updated searchByKeywords, returns LIST of items 8-14-2020\n",
        "def searchByKeywords(gisInfo, searchKeywords):\n",
        "    try:\n",
        "        searchContent = gisInfo.content.search(query=f'{searchKeywords}', item_type='', max_items=50)\n",
        "        x = 0\n",
        "        for z in searchContent:\n",
        "          strMod = str(z.modified)\n",
        "          stampInt = int(strMod[0:10])\n",
        "          print(f'{x} - {z.title} - {z.id} - {z.type} - {z.categories} - {dt.datetime.fromtimestamp(stampInt)}')\n",
        "          x += 1\n",
        "        return searchContent\n",
        "    except:\n",
        "        print('ERROR Search not Successful')\n",
        "\n",
        "# find item by keywords and display visual card\n",
        "def searchByKeyViz(gisInfo, searchKeywords):\n",
        "    try:\n",
        "        searchContent = gisInfo.content.search(query=f'{searchKeywords}', item_type='', max_items=50)\n",
        "        for z in searchContent:\n",
        "            print(f'title: {z.title} - itemID: {z.id} - type: {z.type}')\n",
        "            display(z)\n",
        "    except:\n",
        "        print('ERROR Search not Successful')\n",
        "        \n",
        "# return all keys and values for item when passed itemID string\n",
        "def getItemKeysValues(gisInfo, idString):\n",
        "    try:\n",
        "        getFeature = gisInfo.content.get(idString)\n",
        "        for key, value in getFeature.items():\n",
        "            print(key,': ', value)\n",
        "    except:\n",
        "        print('ERROR GET Keys/Values not Successful')\n",
        "        \n",
        "# takes itemID and gets and returns layerObject if exist, otherwise 'no layers found'\n",
        "def getLayers(gisInfo, idString):\n",
        "    getFeature = gisInfo.content.get(idString)\n",
        "    try:\n",
        "        featureLayers = getFeature.layers\n",
        "        z = 0 \n",
        "        for x in featureLayers:\n",
        "            print(f'Layer {z}: {x}')\n",
        "            z += 1\n",
        "    except:\n",
        "        print('no layers found')\n",
        "    return featureLayers\n",
        "\n",
        "# supply feature layer itemID, and the layer number to display table head \n",
        "def getLayerTable(gisInfo, idString, layerNum):\n",
        "    try:\n",
        "        layerOutput = getLayers(gisInfo, idString)\n",
        "        queryLayer = layerOutput[layerNum].query()\n",
        "        display(queryLayer.sdf.head())\n",
        "    except:\n",
        "        print('ERROR no Layers Found')\n",
        "        \n",
        "# delete item by itemID\n",
        "def deleteItem(gisInfo, idString):\n",
        "    itemToDelete = gisInfo.content.get(idString)\n",
        "    display(itemToDelete)\n",
        "    delQuest = input(f'Are you sure you want to delete: {itemToDelete.title}')\n",
        "    try:\n",
        "        if delQuest.upper() == 'YES':\n",
        "            print(f'DELETING: {itemToDelete.title}')\n",
        "            itemToDelete.delete()\n",
        "        else:\n",
        "            print(f'NOT DELETING: {itemToDelete.title}')\n",
        "    except:\n",
        "        print(f'ERROR failed to DELETE: {itemToDelete.title}')\n",
        "\n",
        "# delete multiple items by searchByKeywords() returned LIST 8-14-2020\n",
        "def delMultiple(gisInfo, itemList):\n",
        "  try:\n",
        "    print('List of Items to be Deleted: ')\n",
        "    for z in itemList:\n",
        "          strMod = str(z.modified)\n",
        "          stampInt = int(strMod[0:10])\n",
        "          print(f'{z.title} - {z.id} - {z.type} - {z.categories} - {dt.datetime.fromtimestamp(stampInt)}')\n",
        "    delQuest = input(f'SURE YOU WANT TO DELETE THESE?!?!?')\n",
        "    if delQuest.upper() == 'YES':\n",
        "      for z in itemList:\n",
        "          print(f'DELETING {z.title}')\n",
        "          itemToDelete = gisInfo.content.get(z.id)\n",
        "          itemToDelete.delete()\n",
        "      print('<FINISHED DELETION PROCESS>')\n",
        "    else:\n",
        "      print(f'NOT DELETING!')\n",
        "  except:\n",
        "      print(f'ERROR failed to DELETE: {itemToDelete.title}')\n",
        "\n",
        "# List all user Dashboards and Dashboard Webmmaps\n",
        "def ListAllDashWebmaps(gisInfo):\n",
        "  source_admin_inventory = get_user_items(gisInfo, gisInfo.users.me)\n",
        "  x = 0\n",
        "  try:\n",
        "    for dashboard in source_admin_inventory['Dashboard']:\n",
        "        print(x, dashboard)\n",
        "        dashWebmap = get_dash_wm(gisInfo, dashboard)\n",
        "        print(dashWebmap)\n",
        "        x += 1\n",
        "  except:\n",
        "    print(\"ERROR COULD NOT LIST DASHBOARDS\") \n",
        "\n",
        "# generic function update targetLayer Features based on Table Records\n",
        "def updateLayFeatFromTable(gisInfo, targetLayerID, matchAttrib, targetAttrib, sourceAttrib):\n",
        "  try:\n",
        "    getLayers = gisInfo.content.get(targetLayerID)\n",
        "    targetLayer = getLayers.layers\n",
        "    layerFeatures = targetLayer[0].query()\n",
        "    sourceTable = getLayers.tables\n",
        "    tableFeatures = sourceTable[0].query()\n",
        "    for tableFeature in tableFeatures:\n",
        "      tableFeatureID = tableFeature.attributes[matchAttrib]\n",
        "      for layerFeature in layerFeatures:\n",
        "        layerFeatureID = layerFeature.attributes[matchAttrib]\n",
        "        if tableFeatureID == layerFeatureID:\n",
        "          targetValue = tableFeature.attributes[sourceAttrib]\n",
        "          layerFeature.set_value(targetAttrib, targetValue)\n",
        "          print(f'feature: {layerFeatureID} from tableFeature: {tableFeatureID} set {targetAttrib} as: {targetValue}')\n",
        "    layerEdits = targetLayer[0].edit_features(updates=layerFeatures)\n",
        "    editCounter = 0\n",
        "    for edits in layerEdits['updateResults']:\n",
        "      editCounter+=1\n",
        "    print(f'updated {getLayers.title} with {editCounter} edits from {getLayers.tables[0]}')\n",
        "  except:\n",
        "    print(f'update features failed for {getLayers.title}')\n",
        "  \n",
        "# generic function update targetLayer Features based on Table Record, adds break list for parameter categories mapping/analysis\n",
        "# 8-14 Updated to screen for sampling records with blank values: 'None'\n",
        "def updateLayFeatFromTableBreaks(gisInfo, targetLayerID, matchAttrib, targetAttrib, sourceAttrib, breaksList):\n",
        "  try:\n",
        "    getLayers = gisInfo.content.get(targetLayerID)\n",
        "    targetLayer = getLayers.layers\n",
        "    layerFeatures = targetLayer[0].query()\n",
        "    sourceTable = getLayers.tables\n",
        "    tableFeatures = sourceTable[0].query()\n",
        "    for tableFeature in tableFeatures:\n",
        "      #tableFeatureID = tableFeature.attributes[matchAttrib]\n",
        "      print(tableFeature.attributes['WATER_TEMP'] is None)\n",
        "      if (tableFeature.attributes['WATER_TEMP'] is None) != True:\n",
        "        tableFeatureID = tableFeature.attributes[matchAttrib]\n",
        "        for layerFeature in layerFeatures:\n",
        "          layerFeatureID = layerFeature.attributes[matchAttrib]\n",
        "          if tableFeatureID == layerFeatureID:\n",
        "            targetValue = tableFeature.attributes[sourceAttrib]\n",
        "            x = 1\n",
        "            for breakVal in breaksList:\n",
        "              if targetValue > breakVal:\n",
        "                print('none')\n",
        "              else:\n",
        "                layerFeature.set_value(targetAttrib, x)\n",
        "                print(f'feature: {layerFeatureID} from tableFeature: {tableFeatureID} set {targetAttrib}: {targetValue} as: {x}')\n",
        "                break\n",
        "              x+=1\n",
        "    layerEdits = targetLayer[0].edit_features(updates=layerFeatures)\n",
        "    editCounter = 0\n",
        "    for edits in layerEdits['updateResults']:\n",
        "      editCounter+=1\n",
        "    # hide REST infor for updated layers and tables\n",
        "    # print(f'updated {getLayers.title} with {editCounter} edits from {getLayers.tables[0]}')\n",
        "    print(f'updated {getLayers.title} with {editCounter} edits')\n",
        "  except:\n",
        "    print(f'update features failed for {getLayers.title}')\n",
        "\n",
        "# download Feature Layer data from AGOL, unzip contents to folder with item.title name\n",
        "# Export Formats: Shapefile | CSV | File Geodatabase | Feature Collection | GeoJson | Scene Package | KML | Excel\n",
        "def downloadItem(gisInfo, idString):\n",
        "    try:\n",
        "        downloadData = gisInfo.content.get(idString)\n",
        "        dataPath = Path('/data')\n",
        "        print(f'Downloading: {downloadData.title} to {dataPath} directory')\n",
        "        if not dataPath.exists():\n",
        "          dataPath.mkdir()\n",
        "        # this portion for feature service\n",
        "        downloadExport = downloadData.export(title=downloadData.title, export_format=\"CSV\")\n",
        "        zipPath = downloadExport.download(save_path=dataPath)\n",
        "        # preparing to extract files to directory with item.title name\n",
        "        #zipPath = downloadData.download(save_path=dataPath)\n",
        "        extractPath = dataPath.joinpath(downloadData.title)\n",
        "        # extract files to /data directory\n",
        "        zipFiles = ZipFile(zipPath)\n",
        "        zipFiles.extractall(path=extractPath)\n",
        "        print(f'list of Files extracted to: {extractPath}')\n",
        "        print(list(file.name for file in extractPath.glob('*')))\n",
        "    except:\n",
        "        print('ERROR DOWNLOAD did not workings!')\n",
        "\n",
        "def searchItem(gisInfo, searchKeywords, itemType):\n",
        "    try:\n",
        "        searchContent = gisInfo.content.search(query=f'{searchKeywords}', item_type=itemType, max_items=25)\n",
        "        if itemType == 'Feature Service':\n",
        "            x = 0\n",
        "            print(f'<Search Query for {searchKeywords}>')\n",
        "            for z in searchContent:\n",
        "                strMod = str(z.modified)\n",
        "                stampInt = int(strMod[0:10])\n",
        "                print(f'{x} - {z.title} - {z.id} - {z.type} - {z.categories} - {dt.datetime.fromtimestamp(stampInt)}')\n",
        "                x += 1\n",
        "            layInd = int(input(f'Index of selected Feature Layer: '))\n",
        "            addLayer = gisInfo.content.get(searchContent[layInd].id)\n",
        "            return addLayer\n",
        "        elif itemType == 'Web Map':\n",
        "            x = 0\n",
        "            print(f'<Search Query for {searchKeywords}>')\n",
        "            for z in searchContent:\n",
        "                strMod = str(z.modified)\n",
        "                stampInt = int(strMod[0:10])\n",
        "                print(f'{x} - {z.title} - {z.id} - {z.type} - {z.categories} - {dt.datetime.fromtimestamp(stampInt)}')\n",
        "                x += 1\n",
        "            layInd = int(input(f'Index of selected Feature Layer: ')) or 'NONE'\n",
        "            #print(searchContent[layInd])\n",
        "            mapReturn = searchContent[layInd]\n",
        "            return mapReturn\n",
        "    except:\n",
        "        print('ERROR Search not Successful')\n",
        "        \n",
        "def quickMap():\n",
        "  mapType = input(f'(YES) for QuickMap (NO) for Existing: ')\n",
        "  if mapType.upper() == 'NO':\n",
        "    mapSize = ['480px','720px','960px']\n",
        "    print(f'<You entered {mapType} please login below>')\n",
        "    userLogin() \n",
        "    mapKeywords = input(f'Name of WebMap to Search for: ') or ''\n",
        "    mapObj = searchItem(gis,mapKeywords,'Web Map')\n",
        "    map = gis.map(mapObj)\n",
        "    sizeIn = int(input(f'MAP SIZE (0)SMALL (1)MEDIUM (2)HUGE: '))\n",
        "    map.layout.height = mapSize[sizeIn]\n",
        "    display(map)\n",
        "  else:\n",
        "    print(f'<You entered {mapType} Opening QuickMap>')\n",
        "    mapList = ['topo','hybrid','streets','dark-gray','terrain']\n",
        "    mapDimen = ['2D','3D']\n",
        "    mapSize = ['480px','720px','960px']\n",
        "    mapLoc = input(f'Location (default=Michigan): ') or 'Michigan'\n",
        "    mapBaseNum = input(f'Basemap (default=topo (1=hybrid,2=streets,3=dark-gray,4=terrain): ') or 0\n",
        "    mapDimIn = input(f'ENTER (1) for 3D Map: ') or 0\n",
        "    atlasLayers = input(f'Layers from Living Atlas(Enter for None): ') or 'NONE'\n",
        "    gisNone = GIS()\n",
        "    map = gisNone.map(mapLoc)\n",
        "    map.basemap = mapList[int(mapBaseNum)]\n",
        "    if atlasLayers != 'NONE':\n",
        "        layerDisplay = searchItem(gisNone, atlasLayers,'Feature Service')\n",
        "        for layrs in layerDisplay.layers:\n",
        "            map.add_layer(layrs)\n",
        "    map.mode = mapDimen[int(mapDimIn)]\n",
        "    sizeIn = int(input(f'MAP SIZE (0)SMALL (1)MEDIUM (2)HUGE: '))\n",
        "    map.layout.height = mapSize[sizeIn]\n",
        "    display(map)\n",
        "\n",
        "# Delete all features from selected Feature Service, may need more debugging\n",
        "def delAllFeatures(gisInfo, idString):\n",
        "    delFeatures = gisInfo.content.get(idString)\n",
        "    display(delFeatures)\n",
        "    delQuest = input(f'Are you sure you want to delete all the feature in? {delFeatures.title}')\n",
        "    try:\n",
        "        if delQuest.upper() == 'YES':\n",
        "            print('in loop')\n",
        "            print(f'DELETING ALL FEATURES IN: {delFeatures.title}')\n",
        "            featDelRes = []\n",
        "            targetLayer = delFeatures.layers\n",
        "            layerFeatures = targetLayer[0].query()\n",
        "            for feature in layerFeatures:\n",
        "              #print(f'features: {feature.attributes}')\n",
        "              featDelRes.append(targetLayer[0].edit_features(deletes=str(feature.attributes['objectid'])))\n",
        "            return featDelRes\n",
        "        else:\n",
        "            print(f'NOT DELETING: {delFeatures.title}')\n",
        "    except:\n",
        "        print(f'ERROR failed to DELETE: {delFeatures.title}')\n",
        "\n",
        "# *******ESRI pre-made helper functions********\n",
        "def is_hosted(gisInfo, item):\n",
        "    return [keyword for keyword in item.typeKeywords if \"Hosted\" in keyword] \n",
        "\n",
        "# Prints all layers in a webmap, very handy\n",
        "def print_webmap_inventory(gisInfo, wm):\n",
        "    wm_obj = WebMap(wm)\n",
        "    print(f\"{wm_obj.item.title}\\n{'-'*100}\")\n",
        "    for wm_layer in wm_obj.layers:\n",
        "        try:\n",
        "            if is_hosted(Item(gisInfo, wm_layer['itemId'])):\n",
        "                print(f\"{' '*2}{wm_layer['title']:40}HOSTED{' ':5}\"\n",
        "                      f\"{wm_layer['layerType']:20}{dict(wm_layer)['itemId']}\")\n",
        "            else:\n",
        "                print(f\"{' '*2}{wm_layer['title']:40}other{' ':6}\"\n",
        "                      f\"{wm_layer['layerType']:20}{wm_layer.id}\") \n",
        "        except:\n",
        "            print(f\"{' '*2}{wm_layer['title']:40}other{' ':6}\"\n",
        "                  f\"{wm_layer['layerType']:20}{wm_layer.id}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "def get_webmap_list(wm):\n",
        "    wm_obj = WebMap(wm)\n",
        "    wmList = []\n",
        "    print(f\"{wm_obj.item.title}\\n{'-'*100}\")\n",
        "    for wm_layer in wm_obj.layers:\n",
        "        # print(wm_layer.itemId)\n",
        "        wmList.append(wm_layer.itemId)\n",
        "    return(wmList)\n",
        "    \n",
        "def displayWebmapLayers(gisInfo, idList):\n",
        "    for id in idList:\n",
        "        displayLayer = gisInfo.content.get(id)\n",
        "        display(displayLayer)\n",
        "\n",
        "def get_user_items(gisInfo, user):\n",
        "    user_inventory = {}\n",
        "    user_items = gisInfo.content.search(query=f\"* AND owner:{user.username}\", \n",
        "                                           max_items=500)\n",
        "    for item in user_items:\n",
        "        if item.type not in user_inventory:\n",
        "            user_inventory[item.type] = [i \n",
        "                                         for i in user_items \n",
        "                                         if i.type == item.type]\n",
        "    return user_inventory\n",
        "\n",
        "def print_user_inventory(inventory):\n",
        "    for itype, ilist in inventory.items():\n",
        "        try:\n",
        "            print(f\"{itype}\\n{'-'*50}\")\n",
        "            for i in ilist:\n",
        "                print(f\"{' ':3}{i.title:50}\")\n",
        "            print(\"\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\t\\tOperation failed on: {i.title}\")\n",
        "            print(f\"\\t\\tException: {sys.exc_info()[1]}\")\n",
        "            continue\n",
        "            \n",
        "def get_dash_wm(gisInfo, dash):\n",
        "    return [gisInfo.content.get(widget['itemId']) \n",
        "            for widget in dash.get_data()['widgets'] \n",
        "            if widget['type'] == \"mapWidget\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2Ha3EWdla7Q",
        "colab_type": "text"
      },
      "source": [
        "# Python API Function List  \n",
        "**userLogin()** - **additionalUserLogin()** - **getUserContent** *(gisInfo)* - **cloneItem** *(gisInfo, gisInfo2, cloneID)*  \n",
        "**searchByKeywords** *(gisInfo, searchKeywords)* - **searchByKeyViz** *(gisInfo, searchKeywords)*  \n",
        "**getItemKeysValues** *(gisInfo, idString)* - **getLayers** *(gisInfo, idString)*\n",
        "**getLayerTable** *(gisInfo, idString, layerNum)* - **deleteItem** *(gisInfo, idString)*  \n",
        "**ListAllDashWebmaps** *(gisInfo)* - **updateLayFeatFromTable** *(gisInfo, targetLayerID, matchAttrib, targetAttrib, sourceAttrib)*  \n",
        "**updateLayFeatFromTableBreaks** *(gisInfo, targetLayerID, matchAttrib, targetAttrib, sourceAttrib, breaksList)*  \n",
        "**downloadItem** *(gisInfo, idString)* - **searchItem** *(gisInfo, searchKeywords, itemType)* - **quickMap()**   \n",
        "**delAllFeatures** *(gisInfo, itemID)* - **delMultiple** *(gisInfo, itemList)*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# ESRI pre-made helper functions  \n",
        "**is_hosted** *(gisInfo, item)* - **print_webmap_inventory** *(gisInfo, wm)* - **get_webmap_list** *(wm)*  \n",
        "**displayWebmapLayers** *(gisInfo, idList)* - **get_user_items** *(gisInfo, user)*  \n",
        "**print_user_inventory** *(inventory)* - **get_dash_wm** *(gisInfo, dash)*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nybZ5ek1_Dvz",
        "colab_type": "text"
      },
      "source": [
        "# Work in Progress Cell(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxb50YBDw56x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#userLogin()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N_bnH54xE6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#searchInput = 'kzoo'\n",
        "#searchByKeywords(gis, searchInput)\n",
        "searchInfo = ''\n",
        "searchType = 'Feature Service'\n",
        "searchReturn = searchItem(gis, searchInfo, searchType)\n",
        "print(searchReturn.id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJWWtg96-iOa",
        "colab_type": "text"
      },
      "source": [
        "# Working to show readable date when item was updated\n",
        "Trying for format ESRI UTC date into standard day-month-year: time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjUsrxnpx4Jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find item by keywords and display text information\n",
        "# recently added proper parsing of dates\n",
        "def searchByKeywords(gisInfo, searchKeywords):\n",
        "    try:\n",
        "        searchContent = gisInfo.content.search(query=f'{searchKeywords}', item_type='', max_items=50)\n",
        "        for z in searchContent:\n",
        "          strMod = str(z.modified)\n",
        "          stampInt = int(strMod[0:10])\n",
        "          print(f'title: {z.title} - itemID: {z.id} - type: {z.type}  - dateEdited: {dt.datetime.fromtimestamp(stampInt)}')\n",
        "    except:\n",
        "        print('ERROR Search not Successful')\n",
        "\n",
        "searchInput = 'water data 2020'\n",
        "searchByKeywords(gis, searchInput)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBl4aQY3zOWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "181db9b8-b146-4335-f0de-837396e70c7a"
      },
      "source": [
        ")x = dt.datetime.now()\n",
        "print(x)\n",
        "formattedTime = x.strftime(\"%m/%d/%Y %X\")\n",
        "print(formattedTime)\n",
        "#print(timeRaw)\n",
        "testTime = time.gmtime(1000)\n",
        "print(testTime)\n",
        "#print(x.year)\n",
        "#print(x.strftime(\"%A\"))\n",
        "#datetimeVal = \n",
        " #   formattedTime = datetime.strftime(datetimeVal, \"%m/%d/%Y\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 19:35:59.579742\n",
            "07/29/2020 07:35:59 PM\n",
            "time.struct_time(tm_year=1970, tm_mon=1, tm_mday=1, tm_hour=0, tm_min=16, tm_sec=40, tm_wday=3, tm_yday=1, tm_isdst=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOa1e1fGFB8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d54ef71b-3d2b-4800-b322-461532e186e1"
      },
      "source": [
        "tm.time()\n",
        "dt.datetime.fromtimestamp(tm.time())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.datetime(2020, 7, 29, 19, 37, 46, 195185)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0fclAc8urE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbaa71e1-eb28-4953-ff5e-7f83b4ed4830"
      },
      "source": [
        "import math\n",
        "x = -0\n",
        "print(math.isnan(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAjJ9kfABtZF",
        "colab_type": "text"
      },
      "source": [
        "# Water Quality Dashboard Display Update Functions\n",
        "Updated KZOO Turb Status 7-23-2020 3:05 pm   \n",
        "Updated NHBP DO Status 7-23-2020 3:08 pm\n",
        "Upated NHBP DO Status 8-12-2020    \n",
        "Updated KZOO Turb Status 8-15-2020 - Refactored Update Layer function, check for 'None'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuEsYMwlB24T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generic function update targetLayer Features based on Table Record, adds break list for parameter categories mapping/analysis\n",
        "# 8-14 Updated to screen for sampling records with blank values: 'None'\n",
        "def updateLayFeatFromTableBreaks(gisInfo, targetLayerID, matchAttrib, targetAttrib, sourceAttrib, breaksList):\n",
        "  try:\n",
        "    getLayers = gisInfo.content.get(targetLayerID)\n",
        "    targetLayer = getLayers.layers\n",
        "    layerFeatures = targetLayer[0].query()\n",
        "    sourceTable = getLayers.tables\n",
        "    tableFeatures = sourceTable[0].query()\n",
        "    for tableFeature in tableFeatures:\n",
        "      #tableFeatureID = tableFeature.attributes[matchAttrib]\n",
        "      print(tableFeature.attributes['WATER_TEMP'] is None)\n",
        "      if (tableFeature.attributes['WATER_TEMP'] is None) != True:\n",
        "        tableFeatureID = tableFeature.attributes[matchAttrib]\n",
        "        for layerFeature in layerFeatures:\n",
        "          layerFeatureID = layerFeature.attributes[matchAttrib]\n",
        "          if tableFeatureID == layerFeatureID:\n",
        "            targetValue = tableFeature.attributes[sourceAttrib]\n",
        "            x = 1\n",
        "            for breakVal in breaksList:\n",
        "              if targetValue > breakVal:\n",
        "                print('none')\n",
        "              else:\n",
        "                layerFeature.set_value(targetAttrib, x)\n",
        "                print(f'feature: {layerFeatureID} from tableFeature: {tableFeatureID} set {targetAttrib}: {targetValue} as: {x}')\n",
        "                break\n",
        "              x+=1\n",
        "    layerEdits = targetLayer[0].edit_features(updates=layerFeatures)\n",
        "    editCounter = 0\n",
        "    for edits in layerEdits['updateResults']:\n",
        "      editCounter+=1\n",
        "    # hide REST infor for updated layers and tables\n",
        "    # print(f'updated {getLayers.title} with {editCounter} edits from {getLayers.tables[0]}')\n",
        "    print(f'updated {getLayers.title} with {editCounter} edits')\n",
        "  except:\n",
        "    print(f'update features failed for {getLayers.title}')\n",
        "\n",
        "#userLogin()\n",
        "kzooLayerNHBP = 'dff379381a6b4b73a1d80b9fd42784a8'\n",
        "kzooLayerLA = '6b62d8b710e64b8abc79015fd7231b87'\n",
        "waterSampNHBP = '680016d676e746f98743f51d28abac60'\n",
        "match = 'SITE_ID'\n",
        "turbTarget = 'TURB_STATUS_'\n",
        "turbSource = 'TURB_NTU'\n",
        "turbRefList = [3.93,10,40,1000]\n",
        "DOtarget = 'DO_STATUS_'\n",
        "DOsource = 'DO_mgl'\n",
        "DOrefList = [5,6,7,100]\n",
        "# calc Turbidity Status from most recent sample\n",
        "#updateLayFeatFromTableBreaks(gis, kzooLayerNHBP, match, turbTarget, turbSource, turbRefList)\n",
        "# calc DO Status from most recent sample\n",
        "updateLayFeatFromTableBreaks(gis, waterSampNHBP, match, DOtarget, DOsource, DOrefList)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpDtkVnf26JB",
        "colab_type": "text"
      },
      "source": [
        "# **Working function to download and process WATER DATA**\n",
        "\n",
        "1.   (COMP) Download and extract WATER_SAMPLING_2020 (itemID: '680016d676e746f98743f51d28abac60')  \n",
        "2.   (COMP) Read Water Data Sample Table as Pandas Dataframe  \n",
        "3. (COMP)Drop uneeded columns/attributes  \n",
        "4. (NEXT STEP) Format correctly for AWQMS upload\n",
        "5. Write as XLS for export to AWQMS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gqKECjl5jyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# downloadReturn and exportAGOLdata work together with specified itemID to \n",
        "# package Export from AGOL into CSV, download and extract files, pass file\n",
        "# path back to export func which creates pandas dataframe, slices off desired \n",
        "# attributes/columns and prints the dataframe head.\n",
        "# NOTE: paths seem to switch the CSV order, one is features, one sample records\n",
        "# Added ExportDataFrame 8-25, works great!\n",
        "def downloadReturn(gisInfo, idString):\n",
        "    try:\n",
        "        downloadData = gisInfo.content.get(idString)\n",
        "        dataPath = Path('/data')\n",
        "        print(f'Downloading: {downloadData.title} to {dataPath} directory')\n",
        "        if not dataPath.exists():\n",
        "          dataPath.mkdir()\n",
        "        # this portion for feature service\n",
        "        downloadExport = downloadData.export(title=downloadData.title, export_format=\"CSV\")\n",
        "        zipPath = downloadExport.download(save_path=dataPath)\n",
        "        # preparing to extract files to directory with item.title name\n",
        "        extractPath = dataPath.joinpath(downloadData.title)\n",
        "        # extract files to /data directory\n",
        "        zipFiles = ZipFile(zipPath)\n",
        "        zipFiles.extractall(path=extractPath)\n",
        "        # delete CSV created by export\n",
        "        print(f'Deleting CSV export generated by Download: {downloadExport.title} ID: {downloadExport.id}')\n",
        "        itemToDelete = gisInfo.content.get(downloadExport.id)\n",
        "        itemToDelete.delete()\n",
        "        print(f'list of Files extracted to: {extractPath}')\n",
        "        print(list(file.name for file in extractPath.glob('*')))\n",
        "        returnArray = []\n",
        "        for x in extractPath.glob('*'):\n",
        "          returnArray.append(x)\n",
        "        return returnArray\n",
        "    except:\n",
        "        print('ERROR DOWNLOAD did not workings!')\n",
        "\n",
        "def exportDataFrame(df,colRename,exportName):\n",
        "  dfRN = df.rename(colRename, axis='columns')\n",
        "  # Very specific edits to generate AWQMS outputs\n",
        "  #dfRN['FIELD Activity ID'] = dfRN['TURB']\n",
        "  # End of VSA\n",
        "  writer = pd.ExcelWriter(exportName, engine='xlsxwriter')\n",
        "  dfRN.to_excel(writer, sheet_name='Sheet1', index=False)\n",
        "  writer.save()\n",
        "  print(f'dataframe successfully exported as: {exportName}')\n",
        "  return dfRN\n",
        "\n",
        "# function to download and process data as specified above\n",
        "def exportAGOLdata(gis, itemID, exportName='exportXLS.xlsx', sliceArray=['BLANK'],colNames={}):\n",
        "  try:\n",
        "    DLdata = downloadReturn(gis, itemID)\n",
        "    if str(DLdata[0])[-5] == '1':\n",
        "      fullPath = DLdata[0]\n",
        "    else: \n",
        "      fullPath = DLdata[1]\n",
        "    print(fullPath)\n",
        "    df = pd.read_csv(fullPath)\n",
        "    display(df.head())\n",
        "    if sliceArray[0] != 'BLANK':\n",
        "      columns = df.columns\n",
        "      columnSlice = columns[sliceArray[0]:sliceArray[1]]\n",
        "      df = df.drop(columnSlice,axis=1)\n",
        "    dfED = exportDataFrame(df,colNames,exportName)\n",
        "    print('<Dataframe Header created from AGOL item Export>')\n",
        "    display(dfED.head().T)\n",
        "    return dfED\n",
        "  except:\n",
        "    print(f'ERROR with {itemID} EXPORT')\n",
        "\n",
        "\n",
        "\n",
        "#userLogin()\n",
        "searchReturn = searchByKeywords(gis, 'water data 2020 Feature Service')\n",
        "indexNumber = input(f'What is the index of the file search target? ')\n",
        "dfEX = exportAGOLdata(gis,searchReturn[int(indexNumber)].id,'xportXLS.xlsx')\n",
        "dfExport = formatXLS(dfEX)\n",
        "dfExport"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot4ZfOd6cVRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# final formatting functions for XLS export\n",
        "\n",
        "#userLogin()\n",
        "searchReturn = searchByKeywords(gis, 'water data 2020 Feature Service')\n",
        "indexNumber = input(f'What is the index of the file search target? ')\n",
        "dfEX = exportAGOLdata(gis,searchReturn[int(indexNumber)].id,'xportXLS.xlsx')\n",
        "dfExport = formatXLS(dfEX)\n",
        "dfExport"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS2DcGyiHpqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Easily creates XLS from dataframe, working 8-25\n",
        "writer = pd.ExcelWriter('demo.xlsx', engine='xlsxwriter')\n",
        "dfEX.to_excel(writer, sheet_name='Sheet1', index=False)\n",
        "writer.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8MrMF5KU9KY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfEX.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdNnrD_YpNEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is SOOOOOO CLOSE!!!\n",
        "#All fields and formatting looks great, just need to add QC conditional tag to the end of Activity ID Field and done!\n",
        "#dfEX\n",
        "#Done 9-8-2020 - Just need to organize!\n",
        "def formatXLS(dfEX):\n",
        "\n",
        "  def actType(QCval):\n",
        "      if QCval == 'Field Measurement':\n",
        "        return 'Field Msr/Obs'\n",
        "      else:\n",
        "        return 'Quality Control Field Replicate Msr/Obs'\n",
        "\n",
        "  def FtoC(Ftemp):\n",
        "    Ctemp = (int(Ftemp) - 32) * (5/9)\n",
        "    return round(Ctemp, 2)\n",
        "\n",
        "  def getDate(dateTime):\n",
        "    splitDate = dateTime.split('/')\n",
        "    #print(f'splitDate: {splitDate}')\n",
        "    if int(splitDate[0]) < 10:\n",
        "      monthName = '0' + splitDate[0]\n",
        "    else:\n",
        "      monthName = splitDate[0]\n",
        "    if int(splitDate[1]) < 10:\n",
        "      dayName = '0' + splitDate[1]\n",
        "    else:\n",
        "      dayName = splitDate[1]\n",
        "    splitDate = splitDate[2].split(' ')\n",
        "    sampYear = splitDate[0]\n",
        "    dateString = (f'{sampYear}{monthName}{dayName}')\n",
        "    return dateString\n",
        "\n",
        "  def getTime(dateTime):\n",
        "    dateSplit = dateTime.split(' ')\n",
        "    timeSplit = dateSplit[1].split(':')\n",
        "    getHours = int(timeSplit[0]) + 7\n",
        "    sampTime24 = str(getHours) + timeSplit[1]\n",
        "    return sampTime24\n",
        "\n",
        "  def isQC(qcInfo):\n",
        "    returnVal = ''\n",
        "    if qcInfo == 'Quality Control Sample Field Replicate':\n",
        "      returnVal = ':QC'\n",
        "    return returnVal\n",
        "\n",
        "  siteList = {'DKC-ST-30':1,'DKC-ST-50':2,'FDP-SD-10':3,'ICD-ST-20':4,'ICD-ST-40':5,'ICD-ST-60':6,'KAR-ST-100':7,'KAR-ST-200':8,'NOT-ST-110':9,'NOT-ST-120':10,'NOT-ST-130':11,'NOT-ST-30':12,'NOT-ST-50':13,'NOT-ST-60':14,'NOT-ST-70':15,'NOT-ST-80':16,'NOT-ST-90':17,'PGC-ST-30':18,'PNC-ST-20':19,'PNC-ST-30':20,'PNC-ST-40':21,'PNC-ST-50':22,'PNC-ST-60':23,'PNC-ST-70':24,'QDP-LA-10':25,'RDP-SD-10':26,'SCD-ST-20':27,'SCD-ST-40':28,'SCD-ST-50':29,'SDP-LA-10':30,'UNT-ST-10':31,'UNT-ST-20':32,'ICD-ST-70':33,'HVC-ST-20':34,'NOT-ST-140':35,'NOT-ST-40':36,'DKC-ST-20':37,'DKC-ST-25':38,'NOT-ST-115':39,'PNC-ST-45':40,'ICD-ST-65':41,'SPC-ST-90':42,'SJR-ST-300':43}\n",
        "\n",
        "  dfV2 = pd.DataFrame()\n",
        "  dfEX['SITE #'] = dfEX.apply(lambda row: siteList[row.SITE_ID], axis=1)\n",
        "  dfV2['SITE #'] = dfEX.apply(lambda row: siteList[row.SITE_ID], axis=1)\n",
        "  numString = 'SITE #'\n",
        "  dfV2['FIELD Activity ID'] = dfEX.apply(lambda row: row.SITE_ID + ':' + str(row['SITE #']) + ':'+ getDate(row.DATE_TIME)+':'+ getTime(row.DATE_TIME) + isQC(row.QC), axis = 1)\n",
        "  dfV2['Activity Type'] = dfEX.apply(lambda x: actType(x['QC']), axis = 1)\n",
        "  dfV2['DATE'] = dfEX.apply(lambda row: row.DATE_TIME[0:8], axis = 1)\n",
        "  dfV2['TIME'] = dfEX.apply(lambda row: row.DATE_TIME[9:19], axis = 1)\n",
        "  dfV2['TEMP C'] = dfEX.apply(lambda x: FtoC(x['WATER_TEMP']), axis = 1)\n",
        "  dfV2['SPCOND'] = dfEX['SPEC_COND_uS_cm']*.001\n",
        "  dfV2['DO%'] = ''\n",
        "  dfV2['pH'] = round(dfEX['pH'],1)\n",
        "  dfCol = ['Monitoring Location','Sample Collection Equipment Name','TEMP F','TURB','DO mg/L','TOT. N mg/L','TOT. P mg/L','E. coli col/100 ml','NOTES']\n",
        "  srcCol = ['SITE_ID','SAMP_EQUIP','WATER_TEMP','TURB_NTU','DO_mgl','TOT_NITRO_','TOT_PHOS_','Ecoli_100ml_','NOTES']\n",
        "\n",
        "  x = 0\n",
        "  for col in dfCol:\n",
        "    dfV2[col] = dfEX[srcCol[x]]\n",
        "    x+=1\n",
        "\n",
        "  dfV2 = dfV2[['FIELD Activity ID','Monitoring Location','SITE #','Activity Type','Sample Collection Equipment Name','DATE','TIME','TEMP C','TEMP F','SPCOND','pH','TURB','DO%','DO mg/L','TOT. N mg/L','TOT. P mg/L','E. coli col/100 ml','NOTES']]\n",
        "  \n",
        "  return dfV2\n",
        "#dfV2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0roZOPLTdi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8eb9522c-0458-4103-9867-33d5ca43281d"
      },
      "source": [
        "siteList = {'DKC-ST-30':1,'DKC-ST-50':2,'FDP-SD-10':3,'ICD-ST-20':4,'ICD-ST-40':5,'ICD-ST-60':6,'KAR-ST-100':7,'KAR-ST-200':8,'NOT-ST-110':9,'NOT-ST-120':10,'NOT-ST-130':11,'NOT-ST-30':12,'NOT-ST-50':13,'NOT-ST-60':14,'NOT-ST-70':15,'NOT-ST-80':16,'NOT-ST-90':17,'PGC-ST-30':18,'PNC-ST-20':19,'PNC-ST-30':20,'PNC-ST-40':21,'PNC-ST-50':22,'PNC-ST-60':23,'PNC-ST-70':24,'QDP-LA-10':25,'RDP-SD-10':26,'SCD-ST-20':27,'SCD-ST-40':28,'SCD-ST-50':29,'SDP-LA-10':30,'UNT-ST-10':31,'UNT-ST-20':32,'ICD-ST-70':33,'HVC-ST-20':34,'NOT-ST-140':35,'NOT-ST-40':36,'DKC-ST-20':37,'DKC-ST-25':38,'NOT-ST-115':39,'PNC-ST-45':40,'ICD-ST-65':41}\n",
        "siteList['HVC-ST-20']\n",
        "siteList[dfEX['SITE_ID'][0]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnjboz2Cey0l",
        "colab_type": "text"
      },
      "source": [
        "# **Explore Excel in Pandas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ2DSu6g-iUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "searchByKeywords(gis, 'water data 2020')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhhh36ol-hED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7afa98f8-d7ea-4347-800c-a4de9380717b"
      },
      "source": [
        "downloadItem(gis, '680016d676e746f98743f51d28abac60')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: WATER_SAMPLING_2020 to /data directory\n",
            "list of Files extracted to: /data/WATER_SAMPLING_2020\n",
            "['WATER_STATIONS_2020_0.csv', 'WATER_DATA_2020_1.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crQbT5fn_M2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import pandas as pd\n",
        "#waterDF = pd.read_csv('/data/WATER_SAMPLING_2020/WATER_DATA_2020_1.csv')\n",
        "#waterDF.head()\n",
        "#waterDF.info()\n",
        "#waterDF.describe()\n",
        "#waterDF[0:5]['SITE_ID']\n",
        "#siteID = waterDF.loc[0]['SITE_ID']\n",
        "#siteID\n",
        "#waterDF.iloc[0]\n",
        "#columns = waterDF.columns\n",
        "#x=0\n",
        "#for col in columns:\n",
        "  #print(x, col)\n",
        "  #x+=1\n",
        "#columns[0:18]\n",
        "#waterDF = waterDF.drop(,axis=1)\n",
        "waterDF.head()\n",
        "writer = pd.ExcelWriter('demo.xlsx', engine='xlsxwriter')\n",
        "writer.save()\n",
        "\n",
        "colSlice = columns[18:31]\n",
        "#for col in colSlice:\n",
        "  #print(col)\n",
        "waterDF = waterDF.drop(colSlice,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLbMVhqdzTH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colSlice = columns[18:31]\n",
        "#for col in colSlice:\n",
        "  #print(col)\n",
        "waterDF = waterDF.drop(colSlice,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEgyRH1Ae9NO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = pd.ExcelWriter('demo.xlsx', engine='xlsxwriter')\n",
        "writer.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGGIwhyFfX_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "heads = ['SITE_ID','WATERBODY']\n",
        "datas = [['PNC-ST-50','NOT-ST-70'],['PINE CREEK','NOTTAWA CREEK']]\n",
        "df = pd.DataFrame(frameData)\n",
        "frameData = {heads[0]:datas[0],heads[1]:datas[1]}\n",
        "df = pd.DataFrame(frameData)\n",
        "writer = pd.ExcelWriter('demo.xlsx', engine='xlsxwriter')\n",
        "df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
        "writer.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hJWAgltgqEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = pd.read_excel('demo.xlsx', index_col=None, no_values=['NA'])\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed86Bb8QhK2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new dataframe with same columns\n",
        "df = pd.DataFrame({'Nsdsdsdadada': ['E','F','G','H'],\n",
        "                   'Age': [100,70,40,60], 'param3': [120,1383,293,283]})\n",
        "writer = pd.ExcelWriter('demo.xlsx', engine='openpyxl')\n",
        "# try to open an existing workbook\n",
        "writer.book = load_workbook('demo.xlsx')\n",
        "# copy existing sheets\n",
        "writer.sheets = dict((ws.title, ws) for ws in writer.book.worksheets)\n",
        "# read existing file\n",
        "reader = pd.read_excel(r'demo.xlsx')\n",
        "# write out the new sheet\n",
        "df.to_excel(writer,index=False,header=False,startrow=len(reader)+1)\n",
        "writer.close()\n",
        "df2 = pd.read_excel('demo.xlsx', index_col=None, no_values=['NA'])\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkVz4g17ebjt",
        "colab_type": "text"
      },
      "source": [
        "# **Pandas Exploration of Titantic Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxihmm6TzFWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezONdPCJat-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titanticDF = pd.read_excel('TitanicTrain.xlsx', index_col=None, no_values=['NA'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezA5yrGobMmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titanticDF.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn15Z3JUbgQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titanticDF.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtezsPwBbr5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#titanticDF.drop()\n",
        "pd.value_counts(titanticDF['Survived']).plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d2W3ssHcSzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1ac0a782-1bba-4306-bf72-dd9bfcf4105d"
      },
      "source": [
        "titanticDF['Survived'].mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3838383838383838"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrFqGCcNcYyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titanticDF.groupby(['Sex']).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFbmRju0c11Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titanticDF.groupby(['Sex','Pclass']).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UfgNuuVdJyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titanticDF[titanticDF['Age']<18].groupby(['Sex','Pclass']).mean()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}